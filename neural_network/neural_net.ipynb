{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "This notebook will cover the mathematical details of a multilayer neural network. This will include feedforward computation and gradient calculation using the backpropagation algorithm\n",
    "\n",
    "## Notation\n",
    "Suppose we have an $L$-layer neural network with a single training example. Let $M_{\\ell}$ be the number of nodes in layer $\\ell$. Let $n^{\\ell}_i$ be neuron number $i$ in layer $\\ell$. Let $b^{\\ell}_i$ be the bias weight of neuron $n^{\\ell+1}_i$. Let $\\Theta^{\\ell}_{i,j}$ be the weight connecting $n^{\\ell}_i$ to $n^{\\ell+1}_j$, making $\\Theta^{\\ell}$ an $M_{\\ell} \\times M_{\\ell+1}$ matrix. Let $a^{\\ell}_i$ be the activation of $n^{\\ell}_i$. Let $g$ be the nonlinear activation function for all nodes in the network. Let $z^{\\ell}_i$ be the sum of all inputs into neuron $n^{\\ell}_i$, such that $a^{\\ell}_i = g(z^{\\ell}_i)$. In this notebook I will treat $z^{\\ell}$, $a^{\\ell}$, $b^{\\ell}$ and other layer-associated vectors ar *row vectors*, which makes more sense to me when we generalize to large numbers of training examples. This may differ from notations used elsewhere.\n",
    "\n",
    "Generalizing to $N$ training examples, $Z^{\\ell}$ and $A^{\\ell}$ become $N \\times M_{\\ell}$ matrices representing the activations of each neuron on layer $\\ell$ for each training example.\n",
    "\n",
    "## Feedforward\n",
    "\n",
    "Prior to nonlinear activation, the input to a certain node is just a weighted sum of activaitons of the previous layer. It follows that $Z^{\\ell+1} = A^{\\ell}\\Theta^{\\ell} + \\mathbf{1}_{N}b^{\\ell}$ where $\\mathbf{1}_N$ is a $N \\times 1$ column vector of ones.\n",
    "Adding our nonlinear activation, we get that $A^{\\ell+1} = g(A^{\\ell}\\Theta^{\\ell} + \\mathbf{1}_{N}b^{\\ell})$ where $g$ is applied element-wise to each entry. If we let $A^{1}$ be the input ot the network, then we can use this recursion to compute $A^{L}$, which is the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import activations as act\n",
    "\n",
    "class WeightLayer:\n",
    "\n",
    "    def __init__(self, weights, biases, activ=act.relu, activ_prime=act.relu_prime):\n",
    "        # weights[i,j] is a weight mapping from neuron i in layer l to j in layer l+1\n",
    "\n",
    "        self.num_inputs = weights.shape[0]\n",
    "        self.num_outputs = weights.shape[1]\n",
    "        self.activ = activ\n",
    "        self.activ_prime = activ_prime\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "\n",
    "    def compute(self, A):  # matrix with inputs from different examples stacked vertically\n",
    "        return self.activ(A @ self.weights + self.biases)\n",
    "\n",
    "    def set_weights(self, new):\n",
    "        self.weights = new\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "\n",
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.num_layers = 0  # input layer by default\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.num_layers += 1\n",
    "\n",
    "    def compute(self, X):\n",
    "        activations = np.empty(self.num_layers + 1, dtype=object)\n",
    "        activations[0] = X\n",
    "        curr_input = X\n",
    "        for l in range(self.num_layers):\n",
    "            curr_input = self.layers[l].compute(curr_input)\n",
    "            activations[l+1] = curr_input\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Computation and Backpropagation\n",
    "\n",
    "While feedforward computation seems straightforward, computing the gradient of a loss function with respect to the weights of the network is significantly more complex. For clarity, we will start by considering the case of a single training example. Supporse we have some loss $C$ which acts on the network output. We define $\\delta^{\\ell}_{i} = \\frac{\\partial C}{\\partial z^{\\ell}_{i}}$. The importance of this particular derivative will become clear momentarily.\n",
    "\n",
    "Define the vector-valued function $f(z^{\\ell}_i) = [z^{\\ell+1}_1, z^{\\ell+1}_2,...,z^{\\ell+1}_{M_{\\ell+1}}]$, assuming $z^{\\ell}_{j\\neq i}$ are all constants.\n",
    "\n",
    "Notice $\\delta^{\\ell}_{i} = \\frac{\\partial C}{\\partial z^{\\ell}_{i}} = \\frac{\\partial C\\left(z^{\\ell+1}_1,z^{\\ell+1}_2,...,z^{\\ell+1}_{M_{\\ell+1}}\\right)}{\\partial z^{\\ell}_{i}} = \\frac{\\partial C(f(z^{\\ell}_i))}{\\partial z^{\\ell}_{i}}$, since the network output is fully determined by $f(z^{\\ell}_i)$\n",
    "\n",
    "Applying the chain rule for Jacobian matrices gives \n",
    "$$\\delta^{\\ell}_{i} = [D C\\left(z^{\\ell+1}_1,z^{\\ell+1}_2,...,z^{\\ell+1}_{M_{\\ell+1}}\\right)][D f(z^{\\ell}_i)] = [\\frac{\\partial C}{z^{\\ell+1}_1}, \\frac{\\partial C}{z^{\\ell+1}_2}, ..., \\frac{\\partial C}{z^{\\ell+1}_{M_{\\ell+1}}}]\\begin{bmatrix} \\Theta^{\\ell}_{i,1}g'(z^{\\ell}_i)\\\\\\Theta^{\\ell}_{i,2}g'(z^{\\ell}_i)\\\\\\vdots\\\\\\Theta^{\\ell}_{i,M_{\\ell+1}}g'(z^{\\ell}_i)\\end{bmatrix} \n",
    "= g'(z^{\\ell}_i) \\sum_{j=1}^{M_{\\ell+1}} \\delta^{\\ell+1}_{j}\\Theta^{\\ell}_{i,j}\n",
    "= [\\delta^{\\ell+1} (\\Theta^{\\ell})^{T}]_i g'(z^{\\ell}_i)$$\n",
    "Therefore we can compute the entire vector using:\n",
    "$\\delta^{\\ell} = \\delta^{\\ell+1} (\\Theta^{\\ell})^{T} .* g'(z^{\\ell})$.\n",
    "\n",
    "When we have multiple training examples, we can just stack the row vectors from each training example on top of eachother. If $\\Delta^{\\ell}$ is a $N \\times M_{\\ell}$ matrix of $\\delta$ values for each training example, then $\\Delta^{\\ell} = \\Delta^{\\ell+1} (\\Theta^{\\ell})^{T} .* g'(Z^{\\ell})$.\n",
    "\n",
    "Remember that our end goal is to compute the gradient of the loss with respect to the the individual weights of the network. Notice:\n",
    "$$\\frac{\\partial C}{\\partial \\Theta^{\\ell}_{i,j}} = \\frac{\\partial C}{\\partial z^{\\ell+1}_{j}}\\frac{\\partial z^{\\ell+1}_j}{\\Theta^{\\ell}_{i,j}}\n",
    "= \\delta^{\\ell+1}_j a^{\\ell}_i$$\n",
    "\n",
    "For N training examples this becomes $\\frac{\\partial C}{\\partial \\Theta^{\\ell}_{i,j}} = \\sum_{k=1}^{N} \\Delta^{\\ell+1}_{k,j} A^{\\ell}_{k,i}$ by the linearity of the derivative, assuming the cost function just adds across training examples.\n",
    "\n",
    "$\\frac{\\partial C}{\\partial \\Theta^{\\ell}_{i,j}} = \\sum_{k=1}^{N} \\Delta^{\\ell+1}_{k,j} A^{\\ell}_{k,i} = \\sum_{k=1}^{N} (A^{\\ell})^{T}_{i,k}\\Delta^{\\ell+1}_{k,j}\n",
    "= [(A^{\\ell})^{T} \\Delta^{\\ell+1}]_{i,j}$\n",
    "\n",
    "Therefore if we let $G^{\\ell}$ be matrix of derivatives with respect to the weights in $\\Theta^{\\ell}$, then $G^{\\ell} = (A^{\\ell})^{T} \\Delta^{\\ell+1}$ \n",
    "\n",
    "Now to derive the gradient with respect to biases:\n",
    "$$\\frac{\\partial C}{\\partial b^{\\ell}_{i}} = \\frac{\\partial C}{\\partial z^{\\ell+1}_{i}}\\frac{\\partial z^{\\ell+1}_i}{b^{\\ell}_{i}}\n",
    "= \\delta^{\\ell+1}_i$$\n",
    "\n",
    "For multiple training examples, it follows that the bias gradient $G^{\\ell}_{b} = \\mathbf{1}^{T}_{N}\\Delta^{\\ell}$ where $\\mathbf{1}^{T}_{N}$ is a row vector of $N$ ones. Equivalently, $G^{\\ell}_{b}$ can be found by summing the columns of $\\Delta^{\\ell}$.\n",
    "\n",
    "### Recap\n",
    "\n",
    "To recap, we can compute the values of $\\Delta^{\\ell}$ by using the recurrence:\n",
    "$$\\Delta^{\\ell} = \\Delta^{\\ell+1} (\\Theta^{\\ell})^{T} .* g'(Z^{\\ell})$$\n",
    "Note that we must still calculate the base case $\\Delta^{L}$ using the gradient of our particular loss function.<br>\n",
    "\n",
    "We then calculate the actual gradients using:\n",
    "$$G^{\\ell} = (A^{\\ell})^{T} \\Delta^{\\ell+1}\\\\\n",
    "G^{\\ell}_{b} = \\mathbf{1}^{T}_{N}\\Delta^{\\ell}$$\n",
    "\n",
    "The next cell adds this functionality to our neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def backpropagate(self, X, Y, cost_gradient):\n",
    "        A = self.compute(X)  # activations of all layers\n",
    "        Delta = np.empty(self.num_layers, dtype=object)\n",
    "        Grad = np.empty(self.num_layers, dtype=object)\n",
    "\n",
    "        Delta[self.num_layers-1] = cost_gradient(A[-1], Y)  # N x K matrix Delta_L\n",
    "        Grad[self.num_layers-1] = A[-2].T @ Delta[-1]\n",
    "\n",
    "        for l in reversed(range(1, self.num_layers)):  # iterate backwards to second layer\n",
    "            Z_l = A[l-1] @ self.layers[l-1].weights + self.layers[l-1].biases\n",
    "            Delta[l-1] = (Delta[l] @ self.layers[l].weights.T) * self.layers[l].activ_prime(Z_l)\n",
    "            Grad[l-1] = A[l-1].T @ Delta[l-1]  # delta indices are down-shifted by 1\n",
    "\n",
    "        Grad_bias = np.array([np.sum(delt, axis=0) for delt in Delta])\n",
    "        return np.concatenate((Grad, Grad_bias))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
